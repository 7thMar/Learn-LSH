{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-level Locality Sensitive Hashing for K-Nearest Neighbor Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import cauchy\n",
    "from sklearn.metrics import euclidean_distances\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as dis\n",
    "import math\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import sys\n",
    "from hashlib import md5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mbyte = 1048576\n",
    "\n",
    "norm_l1 = Normalizer(norm='l1')\n",
    "norm_l2 = Normalizer(norm='l2')\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_md5(H):\n",
    "    hmd5 = md5()\n",
    "    hmd5.update(str(H).encode(encoding='utf-8'))\n",
    "    return hmd5.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def metrics(candidates, approximate_neighbors, exact_neighbors, q, P):\n",
    "    # recall\n",
    "    recall = recall_ratio(candidates, exact_neighbors)\n",
    "    # error\n",
    "    error = error_ratio(q, exact_neighbors, approximate_neighbors, P) \n",
    "    # selectivity\n",
    "    s = selectivity(candidates, P)\n",
    "    return recall, error, s\n",
    "\n",
    "# recall ratio\n",
    "def recall_ratio(candidates, exact_neighbors):\n",
    "    return len(np.intersect1d(candidates, exact_neighbors)) / len(exact_neighbors)\n",
    "\n",
    "# error ratio\n",
    "def error_ratio(v, exact_neighbors, approximate_neighbors, P):\n",
    "    k = len(approximate_neighbors)\n",
    "    exact = np.array([dis.euclidean(v, P[idx]) for idx in exact_neighbors])[:k]\n",
    "    approximate = np.array([dis.euclidean(v, P[idx]) for idx in approximate_neighbors])\n",
    "    return np.sum(exact / approximate) / k\n",
    "\n",
    "# selectivety\n",
    "def selectivity(candidates, P):\n",
    "    return len(candidates) / len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最近邻数据\n",
    "%store -r Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Datasets['SIFT-10K']\n",
    "\n",
    "train_sift = data['train']\n",
    "test_sift = data['test']\n",
    "\n",
    "k_near_neighbors = data['k_near_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = datasets.make_blobs(centers=1, n_features=2, n_samples=10000, random_state=1, cluster_std=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(P[:, 0], P[:, 1], marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diamter(P, n=40):\n",
    "    idxs = np.arange(len(P))\n",
    "    \n",
    "    idx = np.random.randint(len(P))\n",
    "    p = P[idx]\n",
    "    q1_idx = find_farthest(P, p)\n",
    "    q1 = P[q1_idx]\n",
    "    q2_idx = find_farthest(P, q1)\n",
    "    q2 = P[q2_idx]\n",
    "    rho = dis.euclidean(p, q1)\n",
    "    r = dis.euclidean(q1, q2)\n",
    "    r_arr = [r]\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        if p in P:\n",
    "            np.delete(P, idx)\n",
    "        if q1 in P:\n",
    "            np.delete(P, q1_idx)\n",
    "        if len(P) <= 1:\n",
    "            break\n",
    "\n",
    "        p1 = q1 + (r / rho) * (p - q1)\n",
    "        p = 0.5 * (p1 + q1)\n",
    "        q1_idx = find_farthest(P, p)\n",
    "        q1 = P[q1_idx]\n",
    "        q2_idx = find_farthest(P, q1)\n",
    "        q2 = P[q2_idx]\n",
    "        rho = dis.euclidean(p, q1)\n",
    "        r = dis.euclidean(q1, q2)\n",
    "\n",
    "        if r <= r_arr[i - 1]:\n",
    "            return r_arr\n",
    "\n",
    "        r_arr.append(r)\n",
    "\n",
    "    return r_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_farthest(P, q):\n",
    "    return np.argsort(np.array([dis.euclidean(p, q) for p in P]))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "euclidean_distances(P).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "compute_diamter(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(len(P))\n",
    "v = P[np.random.choice(idxs, 2, replace=False)]\n",
    "v = v[1]- v[0]\n",
    "\n",
    "projection = P.dot(v)\n",
    "mid = np.median(projection)\n",
    "\n",
    "idxs_R = np.argwhere(projection >= mid)\n",
    "idxs_L = np.argwhere(projection < mid)\n",
    "R = idxs[np.concatenate(idxs_R)]\n",
    "L = idxs[np.concatenate(idxs_L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([0, v[0]], [0, v[1]])\n",
    "plt.scatter(P[L, 0], P[L, 1])\n",
    "plt.scatter(P[R, 0], P[R, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp_forest_normal(P, n_trees=10, max_depth=None, min_size=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Only support the leafs arg.\n",
    "    \n",
    "    Args:\n",
    "        n_trees: number of trees\n",
    "        max_depth: default(None)\n",
    "        random_state\n",
    "    \n",
    "    Returns:\n",
    "        forest\n",
    "        \n",
    "    \"\"\"\n",
    "    assert max_depth is not None or min_size is not None, \\\n",
    "        \"Should give one of the value of max_depth and min_size\"\n",
    "\n",
    "    if random_state is None:\n",
    "        rand = np.random.RandomState()\n",
    "    else:\n",
    "        rand = np.random.RandomState(random_state)\n",
    "    \n",
    "    forest = []\n",
    "    n, d = P.shape\n",
    "    s_idxs = [] # stack of current index of points\n",
    "                # idxs, parent_node, direction, depth\n",
    "\n",
    "    for i in range(n_trees): # build forest\n",
    "        tree = dict()\n",
    "        s_idxs.append((np.arange(n), tree, 'root', 0, '')) # root node\n",
    "\n",
    "        while len(s_idxs) != 0:\n",
    "            idxs, parent_node, direc, depth, code = s_idxs.pop()\n",
    "\n",
    "            node = dict()\n",
    "\n",
    "            if depth >= max_depth:\n",
    "                node['idxs'] = idxs\n",
    "                parent_node[direc] = node\n",
    "                node['code'] = int(code, 2)\n",
    "                continue\n",
    "\n",
    "            v = idxs[rand.choice(np.arange(len(idxs)), 2, replace=False)] # choose two points randomly\n",
    "            v = P[v[1]]- P[v[0]]\n",
    "            \n",
    "            projection = P[idxs].dot(v)\n",
    "            mid = np.median(projection)\n",
    "            \n",
    "            node['v'] = v\n",
    "            node['split'] = mid\n",
    "\n",
    "            idxs_R = np.argwhere(projection >= mid)\n",
    "            idxs_L = np.argwhere(projection < mid)\n",
    "\n",
    "            if len(idxs_R) == 0 or len(idxs_L) == 0: # 划分失败\n",
    "                continue\n",
    "            \n",
    "            parent_node[direc] = node\n",
    "            \n",
    "            R = idxs[np.concatenate(idxs_R)]\n",
    "            L = idxs[np.concatenate(idxs_L)]\n",
    "\n",
    "            s_idxs.append((R, node, 'r', depth + 1, code + '0'))\n",
    "            s_idxs.append((L, node, 'l', depth + 1, code + '1'))\n",
    "            \n",
    "        forest.append(tree)\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "forest = rp_forest_normal(P, max_depth=8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('random projection tree (mean)')\n",
    "tree = forest[0]\n",
    "plt.figure(figsize=(15, 10))\n",
    "stack = [tree['root']]\n",
    "while len(stack) != 0:\n",
    "    node = stack.pop()\n",
    "    if 'idxs' not in node:\n",
    "        stack.append(node['r'])\n",
    "        stack.append(node['l'])\n",
    "    else:\n",
    "        plt.scatter(P[node['idxs'], 0], P[node['idxs'], 1], marker='x', alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree_normal(tree, q):\n",
    "    node = tree['root']\n",
    "    while 'idxs' not in node:\n",
    "        projection = q.dot(node['v'])\n",
    "        if projection >= node['split']:\n",
    "            node = node['r']\n",
    "        else:\n",
    "            node = node['l']\n",
    "    return node['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_leaf_normal(tree, q):\n",
    "    node = tree['root']\n",
    "    while 'idxs' not in node:\n",
    "        projection = q.dot(node['v'])\n",
    "        if projection >= node['split']:\n",
    "            node = node['r']\n",
    "        else:\n",
    "            node = node['l']\n",
    "    return node['idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_tree_normal(forest[0], P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_nearest_neighbors_normal(forest, q):\n",
    "    candidates = []\n",
    "    for tree in forest:\n",
    "        candidates.append(search_tree_normal(tree, q))\n",
    "    if len(candidates) != 0:\n",
    "        candidates = np.unique(np.concatenate(np.array(candidates)))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp_forest_mean(P, n_trees=10, c=4, max_depth=None, min_size=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Now only support the leafs arg.\n",
    "    \n",
    "    Args:\n",
    "        n_trees: number of trees\n",
    "        depth:\n",
    "        random_state\n",
    "    \n",
    "    Returns:\n",
    "        split\n",
    "        forest\n",
    "        forest_leafs\n",
    "        \n",
    "    \"\"\"\n",
    "    assert max_depth is not None or min_size is not None, \\\n",
    "        \"Should give one of the value of max_depth or min_size\"\n",
    "\n",
    "    if random_state is None:\n",
    "        rand = np.random.RandomState()\n",
    "    else:\n",
    "        rand = np.random.RandomState(random_state)\n",
    "\n",
    "    forest = []\n",
    "    n, d = P.shape\n",
    "    V = dict()\n",
    "    s_idxs = []\n",
    "\n",
    "    for i in range(n_trees):\n",
    "        tree = dict()\n",
    "        s_idxs.append((np.arange(n), tree, 'root', 0, ''))\n",
    "\n",
    "        while len(s_idxs) != 0:\n",
    "            idxs, parent_node, direc, depth, code = s_idxs.pop()\n",
    "\n",
    "            node = dict()\n",
    "\n",
    "            if depth >= max_depth:\n",
    "                node['idxs'] = idxs\n",
    "                parent_node[direc] = node\n",
    "                node['code'] = int(code, 2)\n",
    "                continue\n",
    "                \n",
    "            v = idxs[rand.choice(np.arange(len(idxs)), 2, replace=False)]\n",
    "            v = P[v[1]]- P[v[0]]\n",
    "            node['v'] = v\n",
    "            \n",
    "            diameter = compute_diamter(P[idxs])[-1]\n",
    "\n",
    "            mean_P = P[idxs].mean(axis=0)\n",
    "            dis_P = np.array([dis.euclidean(mean_P, p) for p in P[idxs]])\n",
    "            avg_2_diameter = 2 * np.sum(dis_P ** 2) / len(idxs)\n",
    "#             diameters = []\n",
    "#             select_idxs = idxs[rand.choice(np.arange(len(idxs)), 40, replace=False)]\n",
    "#             for idx in select_idxs:\n",
    "#                 diameters.append(np.array([dis.euclidean(P[idx], p) for p in P[idxs]]).max())\n",
    "#             avg_diameters = np.array(diameters).mean()\n",
    "#             avg_2_diameters = avg_diameters ** 2\n",
    "            \n",
    "            diameter_2 = diameter ** 2\n",
    "            # print(diameter_2, avg_2_diameter)\n",
    "\n",
    "            node['mean'] = mean_P\n",
    "            \n",
    "            if diameter_2 <= c * avg_2_diameter:\n",
    "                projection = P[idxs].dot(v)\n",
    "                split = np.median(projection)\n",
    "                node['split'] = split\n",
    "                node['type'] = 0\n",
    "            else:\n",
    "                projection = dis_P\n",
    "                split = np.median(projection)\n",
    "                node['split'] = split\n",
    "                node['type'] = 1\n",
    "\n",
    "            idxs_R = np.argwhere(projection > split)\n",
    "            idxs_L = np.argwhere(projection <= split)\n",
    "\n",
    "            # print(len(idxs_R), len(idxs_L))\n",
    "            \n",
    "            if len(idxs_R) != 0:\n",
    "                R = idxs[np.concatenate(idxs_R)]\n",
    "            if len(idxs_L) != 0:\n",
    "                L = idxs[np.concatenate(idxs_L)]\n",
    "            \n",
    "            parent_node[direc] = node\n",
    "            \n",
    "            # print(direc)\n",
    "            s_idxs.append((R, node, 'r', depth + 1, code + '0'))\n",
    "            s_idxs.append((L, node, 'l', depth + 1, code + '1'))\n",
    "            \n",
    "        forest.append(tree)\n",
    "\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "forest = rp_forest_mean(P, c=4, max_depth=4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('random projection tree (mean)')\n",
    "tree = forest[0]\n",
    "plt.figure(figsize=(15, 10))\n",
    "stack = [tree['root']]\n",
    "while len(stack) != 0:\n",
    "    node = stack.pop()\n",
    "    if 'idxs' not in node:\n",
    "        stack.append(node['r'])\n",
    "        stack.append(node['l'])\n",
    "    else:\n",
    "        plt.scatter(P[node['idxs'], 0], P[node['idxs'], 1], marker='x', alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree_mean(tree, q):\n",
    "    node = tree['root']\n",
    "    while 'idxs' not in node:\n",
    "        if node['type'] == 1:\n",
    "            projection = np.sqrt(np.sum((q - node['mean']) ** 2)) \n",
    "        else:\n",
    "            projection = q.dot(node['v'])\n",
    "\n",
    "        if projection > node['split']:\n",
    "            node = node['r']\n",
    "        else:\n",
    "            node = node['l']\n",
    "    return node['idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_nearest_neighbors_mean(forest, q):\n",
    "    candidates = []\n",
    "    for tree in forest:\n",
    "        candidates.append(search_tree_mean(tree, q))\n",
    "    if len(candidates) != 0:\n",
    "        candidates = np.unique(np.concatenate(np.array(candidates)))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "q_idx = np.random.randint(10000)\n",
    "print('find P[{}] nearest neighbors'.format(q_idx))\n",
    "q = P[q_idx]\n",
    "# candidates = search_tree(forest[0], q)\n",
    "candidates = find_nearest_neighbors_mean(forest, q)\n",
    "print('number of candidates: {}'.format(len(candidates)))\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(P[:, 0], P[:, 1])\n",
    "plt.scatter(P[candidates, 0], P[candidates, 1])\n",
    "plt.scatter(q[0], q[1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp_forest_max(P, n_trees=10, max_depth=None, min_size=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Now only support the leafs arg.\n",
    "    \n",
    "    Args:\n",
    "        n_trees: number of trees\n",
    "        depth:\n",
    "        random_state\n",
    "    \n",
    "    Returns:\n",
    "        split\n",
    "        forest\n",
    "        forest_leafs\n",
    "        \n",
    "    \"\"\"\n",
    "    assert max_depth is not None or min_size is not None, \\\n",
    "        \"Should give one of the value of max_depth or min_size\"\n",
    "\n",
    "    if random_state is None:\n",
    "        rand = np.random.RandomState()\n",
    "    else:\n",
    "        rand = np.random.RandomState(random_state)\n",
    "    \n",
    "    \n",
    "    forest = []\n",
    "    n, d = P.shape\n",
    "    s_idxs = []\n",
    "\n",
    "    for i in range(n_trees):\n",
    "        tree = dict()\n",
    "        s_idxs.append((np.arange(n), tree, 'root', 0, ''))\n",
    "\n",
    "        while len(s_idxs) != 0:\n",
    "            idxs, parent_node, direc, depth, code = s_idxs.pop()\n",
    "\n",
    "            node = dict()\n",
    "\n",
    "            if depth >= max_depth:\n",
    "                node['idxs'] = idxs\n",
    "                parent_node[direc] = node\n",
    "                node['code'] = int(code, 2)\n",
    "                continue\n",
    "\n",
    "            v = idxs[rand.choice(np.arange(len(idxs)), 2, replace=False)]\n",
    "            v = P[v[1]]- P[v[0]]\n",
    "            node['v'] = v\n",
    "\n",
    "            x = P[idxs[rand.randint(len(idxs))]]\n",
    "            diameter = np.array([dis.euclidean(x, p) for p in P[idxs]]).max()\n",
    "            delta = (rand.rand() * 2 - 1) * diameter / np.sqrt(d)\n",
    "            \n",
    "            projection = P[idxs].dot(v)\n",
    "\n",
    "            split = np.median(projection) + delta\n",
    "\n",
    "            node['split'] = split            \n",
    "\n",
    "            idxs_R = np.argwhere(projection > split)\n",
    "            idxs_L = np.argwhere(projection <= split)\n",
    "\n",
    "            if len(idxs_R) != 0:\n",
    "                R = idxs[np.concatenate(idxs_R)]\n",
    "            if len(idxs_L) != 0:\n",
    "                L = idxs[np.concatenate(idxs_L)]\n",
    "            \n",
    "            parent_node[direc] = node\n",
    "\n",
    "            s_idxs.append((R, node, 'r', depth + 1, code + '0'))\n",
    "            s_idxs.append((L, node, 'l', depth + 1, code + '1'))\n",
    "            \n",
    "        forest.append(tree)\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "forest = rp_forest_max(P, max_depth=4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('random projection tree (mean)')\n",
    "tree = forest[0]\n",
    "plt.figure(figsize=(15, 10))\n",
    "stack = [tree['root']]\n",
    "while len(stack) != 0:\n",
    "    node = stack.pop()\n",
    "    if 'idxs' not in node:\n",
    "        stack.append(node['r'])\n",
    "        stack.append(node['l'])\n",
    "    else:\n",
    "        plt.scatter(P[node['idxs'], 0], P[node['idxs'], 1], marker='x', alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def search_tree_max(tree, q):\n",
    "    node = tree['root']\n",
    "    while 'idxs' not in node:\n",
    "        projection = q.dot(node['v'])\n",
    "        if projection > node['split']:\n",
    "            node = node['r']\n",
    "        else:\n",
    "            node = node['l']\n",
    "            \n",
    "    return node['idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_nearest_neighbors_max(forest, q):\n",
    "    candidates = []\n",
    "    for tree in forest:\n",
    "        candidates.append(search_tree_max(tree, q))\n",
    "    if len(candidates) != 0:\n",
    "        candidates = np.unique(np.concatenate(np.array(candidates)))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "q_idx = np.random.randint(10000)\n",
    "print('find P[{}] nearest neighbors'.format(q_idx))\n",
    "q = P[q_idx]\n",
    "# candidates = search_tree(forest[0], q)\n",
    "candidates = find_nearest_neighbors_max(forest, q)\n",
    "print('number of candidates: {}'.format(len(candidates)))\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(P[:, 0], P[:, 1], marker='x')\n",
    "plt.scatter(P[candidates, 0], P[candidates, 1], marker='x')\n",
    "plt.scatter(q[0], q[1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLevelIndex(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset_ = dataset\n",
    "        self.n_, self.d_ = dataset.shape\n",
    "        \n",
    "    def build_forest(self, n_trees=10):\n",
    "        pass\n",
    "    \n",
    "    def get_nns(self, query, k=1):\n",
    "        pass\n",
    "    \n",
    "    def recall(self, test):\n",
    "        pass\n",
    "    \n",
    "    def precision(self, test):\n",
    "        pass\n",
    "    \n",
    "    def hashing_time(self, test):\n",
    "        pass\n",
    "    \n",
    "    def query_time(self, test):\n",
    "        pass\n",
    "    \n",
    "    def score(self, test):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RP tree 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def rp_forest_3rd(P, n_trees=10, max_depth=None, min_size=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Now only support the leafs arg.\n",
    "    \n",
    "    Args:\n",
    "        n_trees: number of trees\n",
    "        depth:\n",
    "        random_state\n",
    "    \n",
    "    Returns:\n",
    "        split\n",
    "        forest\n",
    "        forest_leafs\n",
    "        \n",
    "    \"\"\"\n",
    "    assert max_depth is not None or min_size is not None, \\\n",
    "        \"Should give one of the value of max_depth or min_size\"\n",
    "\n",
    "    if random_state is None:\n",
    "        rand = np.random.RandomState()\n",
    "    else:\n",
    "        rand = np.random.RandomState(random_state)\n",
    "    \n",
    "    c = 2\n",
    "    forest = []\n",
    "    n, d = P.shape\n",
    "    s_idxs = []\n",
    "\n",
    "    for i in range(n_trees):\n",
    "        tree = dict()\n",
    "        s_idxs.append((np.arange(n), tree, 'root', 0))\n",
    "\n",
    "        while len(s_idxs) != 0:\n",
    "            idxs, parent_node, direc, depth = s_idxs.pop()\n",
    "\n",
    "            node = dict()\n",
    "\n",
    "            if depth >= max_depth:\n",
    "                node['idxs'] = idxs\n",
    "                parent_node[direc] = node\n",
    "                continue\n",
    "\n",
    "            v = idxs[rand.choice(np.arange(len(idxs)), 2, replace=False)]\n",
    "            v = P[v[1]] - P[v[0]]\n",
    "            node['v'] = v\n",
    "\n",
    "            diameter = compute_diamter(P[idxs])\n",
    "\n",
    "            diameters = []\n",
    "            select_idxs = idxs[rand.choice(np.arange(len(idxs)), 40, replace=False)]\n",
    "            for idx in select_idxs:\n",
    "                diameters.append(np.array([dis.euclidean(P[idx], p) for p in P[idxs]]).max())\n",
    "            avg_diamters = diameters.mean()\n",
    "            avg_2_diamters = avg_diamters ** 2\n",
    "            \n",
    "            diameter_2 = diameter ** 2\n",
    "            print(diameter_2, avg_2_diamters)\n",
    "            \n",
    "            if diameter_2 <= c * avg_2_diamters:\n",
    "                projection = P[idxs].dot(v)\n",
    "                \n",
    "            split = np.median(projection) + delta\n",
    "            projection = P[idxs].dot(v)\n",
    "            node['split'] = split            \n",
    "\n",
    "            # print(projection)\n",
    "            idxs_R = np.argwhere(projection > split)\n",
    "            idxs_L = np.argwhere(projection <= split)\n",
    "        \n",
    "            # print(len(idxs_R), len(idxs_L))\n",
    "            \n",
    "            if len(idxs_R) != 0:\n",
    "                R = idxs[np.concatenate(idxs_R)]\n",
    "            if len(idxs_L) != 0:\n",
    "                L = idxs[np.concatenate(idxs_L)]\n",
    "            \n",
    "            parent_node[direc] = node\n",
    "            \n",
    "            # print(direc)\n",
    "            s_idxs.append((R, node, 'r', depth + 1))\n",
    "            s_idxs.append((L, node, 'l', depth + 1))\n",
    "            \n",
    "        forest.append(tree)\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Modeling LSH for Performan Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "f_{\\kappa, \\theta}(x) = \\alpha(\\frac{x}{\\theta})^\\kappa e^{-x/\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "D = 2(\\kappa + 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "E: 算术平均值  \n",
    "\n",
    "G: 几何平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\kappa \\theta = E \\\\\n",
    "\\text{ln}(\\kappa) - \\psi(\\kappa) = \\text{ln}(E) - \\text{ln}(G)   \n",
    "\\end{cases} \\\\\n",
    "\\psi(x) = \\frac{\\Gamma^{'}(x)}{\\Gamma(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### For $X^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gmean(arr):\n",
    "    return arr.prod() ** (1.0/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats.mstats import gmean\n",
    "from scipy.special import digamma\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_select = 1000\n",
    "idxs_select = np.random.choice(np.arange(10000), (n_select, 2), replace=False)\n",
    "d_select = np.array([euclidean(P[idxs[0]], P[idxs[1]]) for idxs in idxs_select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "E = (d_select**2).mean()\n",
    "G = gmean(d_select**2)\n",
    "print('E: {:.4f}, G: {:.4f}'.format(E, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "equation_right = np.log(E) - np.log(G)\n",
    "Kappa = np.arange(1, 5, 0.5)\n",
    "result = np.log(Kappa) - digamma(Kappa)\n",
    "plt.plot(Kappa, result)\n",
    "plt.xticks(Kappa)\n",
    "plt.hlines(y=equation_right, xmin=Kappa[0], xmax=Kappa[-1])\n",
    "plt.xlabel('kappa')\n",
    "plt.ylabel('equation left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kappa = 1\n",
    "theta = E / kappa\n",
    "print('kappa: {}, theta: {:.4f}'.format(kappa, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds = np.array([[euclidean(P[i], p) for p in P] for i in np.random.choice(np.arange(10000), 40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds = np.sort(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "order_ds = ds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp = np.linspace(gamma.ppf(0.01, a=kappa, scale=theta), gamma.ppf(0.99, a=kappa, scale=theta), 100)\n",
    "pd = gamma.pdf(pp, a=kappa, scale=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(order_ds**2, bins=100, density=True)\n",
    "plt.plot(pp, pd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### For $X_k^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "E[X_k] = \\frac{[\\Gamma(1+\\frac{D_1}{2})]^{\\frac{1}{D_1}}}{\\sqrt \\pi}(\\frac{k}{N-1})^\\frac{1}{D_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "E_k = \\alpha k^\\beta N^\\gamma \\\\\n",
    "G_k = \\alpha ^{'} k^{\\beta'} N^{\\gamma'}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_anchors = 100\n",
    "n = 10000\n",
    "idxs_P = np.arange(n)\n",
    "idxs_anchor = np.random.choice(np.arange(10000), n_anchors, replace=False)\n",
    "\n",
    "idxs_rest = np.setdiff1d(idxs_P, idxs_anchor)\n",
    "\n",
    "points_anchor = P[idxs_anchor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = np.arange(1000, len(idxs_rest), 1000)\n",
    "K = np.arange(50, 501, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idxs_samples = np.array([np.random.choice(np.arange(len(idxs_rest)), n, replace=False) for n in N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "d_knns = []\n",
    "for q in points_anchor:\n",
    "    d_ns = []\n",
    "    for idxs_sample in idxs_samples:\n",
    "        d_ks = []\n",
    "        ds = np.array([euclidean(q, p) for p in P[idxs_sample]])\n",
    "        sort_ds = np.sort(ds)\n",
    "        for k in K:\n",
    "            d_ks.append(sort_ds[k])\n",
    "        d_ns.append(d_ks)\n",
    "    d_knns.append(d_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_knns = np.array(d_knns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_knns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_1e4_knns = d_knns[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fix_n_1e4_mean = (d_1e4_knns ** 2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fix_n_1e4_gmean = (d_1e4_knns ** 2).prod(axis=0) ** (1 / n_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(K, fix_n_1e4_mean, label='mean', marker='x')\n",
    "plt.plot(K, fix_n_1e4_gmean, label='gmean', marker='>')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nks = d_knns.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pr(w, c):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        w: 段长\n",
    "        c: r1, r2, 距离\n",
    "    \"\"\"\n",
    "    a = 2 * norm.cdf(-w/c)\n",
    "    b = 2 / (np.sqrt(2 * np.pi) * w / c)\n",
    "    d = np.e ** (-((w**2) / (2 * (c ** 2))))    \n",
    "    return 1 - a - b * (1 - d)\n",
    "    \n",
    "def compute_rho(p1, p2):\n",
    "    return (np.log(1/p1) / np.log(1/p2))\n",
    "\n",
    "def compute_r1(P):\n",
    "    d = P.shape[1]\n",
    "    print('Estimate r1')\n",
    "    print('P: {}'.format(P.shape))\n",
    "\n",
    "#     n = P.shape[0] * 0.03\n",
    "    n = 20\n",
    "    nn = int(np.log(P.shape[0]))\n",
    "    print('sample {} points, calculate near {} neighbors.'.format(n, nn))\n",
    "    idx = np.random.choice(P.shape[0], size=n, replace=False)\n",
    "    qs = P[idx]\n",
    "    r1_avg = []\n",
    "    for q in qs:\n",
    "        dist_arr = np.array([dis.euclidean(q, p) for p in P])\n",
    "        dist_sort = np.sort(dist_arr)\n",
    "        avg = np.sort(dist_arr)[1:nn+1].mean()\n",
    "        r1_avg.append(avg)\n",
    "\n",
    "    r1 = np.array(r1_avg).mean()\n",
    "    print('estimate r1 = {}'.format(r1))\n",
    "    return r1\n",
    "\n",
    "def draw_W(P, c=2):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        绘制图像，观察最优 w 值\n",
    "    Args:\n",
    "        c: 近似因子\n",
    "    \"\"\"\n",
    "    r1 = compute_r1(P)\n",
    "    r2 = c * r1\n",
    "    W = np.arange(r1 / 2, r1 * 10, r1 / 2)\n",
    "\n",
    "    p1 = [compute_pr(w, r1) for w in W]\n",
    "    p2 = [compute_pr(w, c * r1) for w in W]\n",
    "    rho = [compute_rho(p1[i], p2[i]) for i in range(len(W))]\n",
    "\n",
    "    plt.plot(W, p1, label='p1')\n",
    "    plt.plot(W, p2, label='p2')\n",
    "    plt.plot(W, rho, label='rho')\n",
    "    plt.hlines(y=1/c, xmin=0, xmax=r1 * 10, label='1/c')\n",
    "    plt.xlabel('w')\n",
    "    plt.ylabel('p')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_AB(d, M, W, L, random_state=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        d: dim\n",
    "        M: same as k\n",
    "        W: interval\n",
    "        L: number of hash tables\n",
    "    Returns:\n",
    "        A: L * M * d\n",
    "        B: L * M\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        rand = np.random.RandomState()\n",
    "    else:\n",
    "        rand = np.random.RandomState(random_state)\n",
    "    A = rand.normal(0, 1, (L, M, d))\n",
    "    B = rand.uniform(0, W, (L, M))\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashing(v, a, b, W):\n",
    "    return (a.dot(v) + b) / W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Z^8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morton Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.random.randint(0, 6, (10000, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bit = len(bin(V.max())[2:])\n",
    "max_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morton_curve(v, max_bit):\n",
    "    bin_codes = np.array([bin(i) for i in v])\n",
    "    codes = []\n",
    "    for i, code in enumerate(bin_codes):\n",
    "        codes.append(code[2:])\n",
    "        n = len(codes[i])\n",
    "        for j in range(max_bit - n):\n",
    "            codes[i] = '0' + codes[i]\n",
    "\n",
    "    result = ''.join(np.array(list(map(list, codes))).T.reshape(1, -1)[0])\n",
    "    return int(result, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "morton_numbers = [morton_curve(v, max_bit) for v in V]\n",
    "morton_numbers.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**四的倍数？如何判断相邻？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $E_8$ Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = np.random.rand(8) + np.random.randint(0, 10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = v.round()\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = (v - 1/2).round() + 1/2\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis.euclidean(v, v1), dis.euclidean(v, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Z^M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10, 20, 30]\n",
    "M = 8\n",
    "k = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('random projection tree (mean)')\n",
    "tree = forest[0]\n",
    "stack = [(tree['root'], '')]\n",
    "\n",
    "while len(stack) != 0:\n",
    "    node, code = stack.pop()\n",
    "    if 'idxs' not in node:\n",
    "        stack.append((node['r'], code + '0'))\n",
    "        stack.append((node['l'], code + '1'))\n",
    "    else:\n",
    "        print(int(code, 2))\n",
    "        print(len(node['idxs']))\n",
    "        draw_W(train_sift[node['idxs']])\n",
    "        idxs = node['idxs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_W(train_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.arange(500, 2100, 100)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = generate_AB(d=d, L=L[0], M=M, W=W[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level 2: Store points into buckets')\n",
    "\n",
    "def construct_tables(forest, P, A, B, L, W):\n",
    "    trees = [] # n trees\n",
    "    for tree in forest:\n",
    "        nodes = dict() # 16 nodes\n",
    "        stack = [tree['root']]\n",
    "        while len(stack) != 0:\n",
    "            node = stack.pop()\n",
    "            if 'idxs' not in node:\n",
    "                stack.append((node['r']))\n",
    "                stack.append((node['l']))\n",
    "            else:\n",
    "                code = node['code']\n",
    "                tables = [] # L buckets\n",
    "                idxs = node['idxs']\n",
    "\n",
    "                # Level 2\n",
    "                for i in range(L):\n",
    "                    buckets = dict() # n bucket\n",
    "                    H = np.floor((P[idxs].dot(A[i].T) + B[i]) / W)\n",
    "                    for j, h in enumerate(H):\n",
    "                        bi = generate_md5(h)\n",
    "                        if bi in buckets:\n",
    "                            buckets[bi].append(idxs[j])\n",
    "                        else:\n",
    "                            buckets[bi] = [idxs[j]]\n",
    "                    tables.append(buckets)\n",
    "\n",
    "                nodes[code] = tables\n",
    "\n",
    "        trees.append(nodes)\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trees: array, n 棵树\n",
    "    - nodes: dict, 16 个叶子节点, key=code\n",
    "        - tables: array, L 个哈希表\n",
    "            - buckets: dict, m 个哈希桶, key=bucket_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trees = construct_tables(forest, train_sift, A, B, L[0], W[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = test_sift[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Tree Node Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaf_codes(forest, q):\n",
    "    leaf_codes = []\n",
    "    for tree in forest:\n",
    "        leaf_codes.append(search_tree_normal(tree, q))\n",
    "    return leaf_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_codes = find_leaf_codes(forest, q)\n",
    "leaf_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_near_neighbors(trees, leaf_codes, q, A, B, L, W):\n",
    "    result = []\n",
    "    for i, code in enumerate(leaf_codes):\n",
    "        tree = trees[i]\n",
    "        node = tree[code]\n",
    "        for j in range(L):\n",
    "            h = np.floor((A[j].dot(q) + B[j]) / W)\n",
    "            bi = generate_md5(h)\n",
    "            if bi in node[j]:\n",
    "                result.append(node[j][bi])\n",
    "    return np.unique(np.concatenate(np.array(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = find_near_neighbors(trees, leaf_codes, q, A, B, L[0], W[-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_nearest_neighbors(P, q, near_neighbors_idxs, K=50):\n",
    "    if len(near_neighbors_idxs) < K:\n",
    "        print('number of candidates less than K')\n",
    "        print('K = number of candidates')\n",
    "        K = len(near_neighbors_idxs)\n",
    "    return near_neighbors_idxs[np.argsort(np.array(\n",
    "        [dis.euclidean(q, p) for p in P[near_neighbors_idxs]])\n",
    "                                         )[:K]\n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_neighbors = find_k_nearest_neighbors(train_sift, q, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[0], \n",
    "                           q, train_sift)\n",
    "\n",
    "print('recall = {:.4f}'.format(recall))\n",
    "print('error  = {:.4f}'.format(error))\n",
    "print('selevtivity = {:.4f}'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "W =  np.arange(1500, 2100, 100)\n",
    "M = 8\n",
    "K = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for l in L:\n",
    "    for w in W:\n",
    "        # 1. 构造 rp-tree\n",
    "        forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "        # 2. 构造 hash table\n",
    "        A, B = generate_AB(d=d, L=l, M=M, W=w)\n",
    "        trees = construct_tables(forest, train_sift, A, B, l, w)\n",
    "        \n",
    "        result = dict()\n",
    "        result['params'] = dict()\n",
    "        result['params']['L'] = l\n",
    "        result['params']['W'] = w\n",
    "        \n",
    "        print('L = {}, W = {}'.format(l, w))\n",
    "\n",
    "        recall_arr = []\n",
    "        error_arr = []\n",
    "        selectivity_arr = []\n",
    "        # 3. 查询点\n",
    "        for i, q in enumerate(test_sift):\n",
    "            leaf_codes = find_leaf_codes(forest, q)\n",
    "            \n",
    "            # 4. 获取 候选集 candidates\n",
    "            candidates = find_near_neighbors(trees, leaf_codes, q, A, B, l, w) \n",
    "\n",
    "            # 5. 计算 近似 k近邻\n",
    "            approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "            # 6. 评估\n",
    "            recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[i], \n",
    "                           q, train_sift)\n",
    "            \n",
    "            recall_arr.append(recall)\n",
    "            error_arr.append(error)\n",
    "            selectivity_arr.append(s)\n",
    "        result['metrics'] = dict()\n",
    "        result['metrics']['recall'] = sum(recall_arr) / len(test_sift)\n",
    "        result['metrics']['error'] = sum(error_arr) / len(test_sift)\n",
    "        result['metrics']['selectivity'] = sum(selectivity_arr) / len(test_sift)\n",
    "    \n",
    "        metric_results['ZM'].append(result)\n",
    "#         results.append(result)\n",
    "    \n",
    "# metric_results['ZM'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results['ZM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "w = 800\n",
    "# 1. 构造 rp 树\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "# 2. 构造 hash table\n",
    "A, B = generate_AB(d=d, L=l, M=M, W=w)\n",
    "trees = construct_tables(forest, train_sift, A, B, l, w)\n",
    "\n",
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "# 3. 查询点\n",
    "for i, q in enumerate(test_sift):\n",
    "    leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "    # 4. 获取 候选集 candidates\n",
    "    candidates = find_near_neighbors(trees, leaf_codes, q, A, B, l, w) \n",
    "\n",
    "    # 5. 计算 近似 k近邻\n",
    "    approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "    # 6. 评估\n",
    "    recall, error, s = metrics(candidates, \n",
    "                   approximate_neighbors, \n",
    "                   k_near_neighbors[i], \n",
    "                   q, train_sift)\n",
    "\n",
    "    recall_arr.append(recall)\n",
    "    error_arr.append(error)\n",
    "    selectivity_arr.append(s)\n",
    "\n",
    "print('L = {}, W = {}'.format(l, w))\n",
    "print('recall = {:.4f}'.format(sum(recall_arr) / len(test_sift)))\n",
    "print('error  = {:.4f}'.format(sum(error_arr) / len(test_sift)))\n",
    "print('selevtivity = {:.4f}'.format(sum(selectivity_arr) / len(test_sift)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "for result in metric_results['ZM']:\n",
    "    selectivity_arr.append(result['metrics']['selectivity'])\n",
    "    recall_arr.append(result['metrics']['recall'])\n",
    "    error_arr.append(result['metrics']['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='recall ratio')\n",
    "plt.plot(selectivity_arr, error_arr, marker='x', label='error ratio')\n",
    "plt.title('Standard, $Z^M$, M=8, L=10', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $E_8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E8_decode(h, decode_type='E8'):\n",
    "    D8 = h.round().astype(np.int)\n",
    "    total = D8.sum()\n",
    "    if total % 2 != 0:\n",
    "        h2 = np.abs(np.modf(h)[0])\n",
    "        h3 = h2.copy()\n",
    "        # 排序\n",
    "        h3[h3 < 0.5] = 0.5 - h3[h3 < 0.5]\n",
    "        h3[h3 > 0.5] = h3[h3 > 0.5] - 0.5\n",
    "        order = h3.argsort()\n",
    "\n",
    "    i = 0\n",
    "    while total % 2 != 0: # 或许没有必要？\n",
    "        if h2[order[i]] > 0.5:\n",
    "            D8[order[i]] -= 1\n",
    "        else:\n",
    "            D8[order[i]] += 1\n",
    "        total = D8.sum()\n",
    "        i += 1\n",
    "    \n",
    "    if decode_type == 'E8':\n",
    "        D812 = E8_decode(h - 1/2, 'D8') + 1/2 # 递归求解 D8 + 1/2\n",
    "        \n",
    "        d1 = dis.euclidean(h, D8)\n",
    "        d2 = dis.euclidean(h, D812)\n",
    "        \n",
    "        if d1 > d2:\n",
    "            return D812\n",
    "        else:\n",
    "            return D8\n",
    "    else:\n",
    "        return D8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E8 = E8_decode(h)\n",
    "E8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level 2: Store points into buckets')\n",
    "\n",
    "def construct_tables_E8(forest, P, A, B, L, W):\n",
    "    trees = [] # n trees\n",
    "    for tree in forest:\n",
    "        nodes = dict() # 16 nodes\n",
    "        stack = [tree['root']]\n",
    "        while len(stack) != 0:\n",
    "            node = stack.pop()\n",
    "            if 'idxs' not in node:\n",
    "                stack.append((node['r']))\n",
    "                stack.append((node['l']))\n",
    "            else:\n",
    "                code = node['code']\n",
    "                tables = [] # L buckets\n",
    "                idxs = node['idxs']\n",
    "\n",
    "                # Level 2\n",
    "                for i in range(L):\n",
    "                    E8 = dict() # n bucket\n",
    "                    H = (P[idxs].dot(A[i].T) + B[i]) / W\n",
    "                    \n",
    "                    for j, h in enumerate(H):\n",
    "                        E8_code = E8_decode(h)\n",
    "                        bi = generate_md5(E8_code)\n",
    "                        if bi in E8:\n",
    "                            E8[bi].append(idxs[j])\n",
    "                        else:\n",
    "                            E8[bi] = [idxs[j]]\n",
    "                    \n",
    "                    tables.append(E8)\n",
    "\n",
    "                nodes[code] = tables\n",
    "\n",
    "        trees.append(nodes)\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_near_neighbors_E8(trees, leaf_codes, q, A, B, L, W, M):\n",
    "    result = []\n",
    "    for i, code in enumerate(leaf_codes):\n",
    "        tree = trees[i]\n",
    "        node = tree[code]\n",
    "        for j in range(L):\n",
    "            E8 = node[j] # morton curve\n",
    "            h = (A[j].dot(q) + B[j]) / W\n",
    "            E8_code = E8_decode(h)\n",
    "            \n",
    "            bi = generate_md5(E8_code)\n",
    "            if bi in E8:\n",
    "                result.append(E8[bi])\n",
    "                \n",
    "    return np.unique(np.concatenate(np.array(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "W =  np.arange(1400, 2100, 100)\n",
    "M = 8\n",
    "K = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "metric_results['E8'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for l in L:\n",
    "    for w in W:\n",
    "        # 1. 构造 rp 树\n",
    "        forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "        # 2. 构造 hash table\n",
    "        A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "        trees = construct_tables_E8(forest, train_sift, A, B, l, w)\n",
    "        \n",
    "        result = dict()\n",
    "        result['params'] = dict()\n",
    "        result['params']['L'] = l\n",
    "        result['params']['W'] = w\n",
    "        \n",
    "        print('L = {}, W = {}'.format(l, w))\n",
    "        recall_arr = []\n",
    "        error_arr = []\n",
    "        selectivity_arr = []\n",
    "\n",
    "        # 3. 查询点\n",
    "        for i, q in enumerate(test_sift):\n",
    "            leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "            # 4. 获取 候选集 candidates multiprobe\n",
    "            candidates = find_near_neighbors_E8(trees, leaf_codes, q, A, B, l, w, M) \n",
    "\n",
    "            # 5. 计算 近似 k近邻\n",
    "            approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "            \n",
    "            # 6. 评估\n",
    "            recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[i], \n",
    "                           q, train_sift)\n",
    "            \n",
    "            recall_arr.append(recall)\n",
    "            error_arr.append(error)\n",
    "            selectivity_arr.append(s)\n",
    "            \n",
    "        result['metrics'] = dict()\n",
    "        result['metrics']['recall'] = sum(recall_arr) / len(test_sift)\n",
    "        result['metrics']['error'] = sum(error_arr) / len(test_sift)\n",
    "        result['metrics']['selectivity'] = sum(selectivity_arr) / len(test_sift)\n",
    "    \n",
    "        metric_results['E8'].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric_results['E8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_arr_E8 = []\n",
    "error_arr_E8 = []\n",
    "selectivity_arr_E8 = []\n",
    "for result in metric_results['E8']:\n",
    "    selectivity_arr_E8.append(result['metrics']['selectivity'])\n",
    "    recall_arr_E8.append(result['metrics']['recall'])\n",
    "    error_arr_E8.append(result['metrics']['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr_E8, recall_arr_E8, marker='x', label='recall ratio')\n",
    "plt.plot(selectivity_arr_E8, error_arr_E8, marker='x', label='error ratio')\n",
    "plt.title('Standard, $E_8$, M=8, L=10', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "w = 1100\n",
    "# 1. 构造 rp 树\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "# 2. 构造 hash table\n",
    "A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "trees = construct_tables_E8(forest, train_sift, A, B, l, w)\n",
    "\n",
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "\n",
    "# 3. 查询点\n",
    "for i, q in enumerate(test_sift):\n",
    "    leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "    # 4. 获取 候选集 candidates multiprobe\n",
    "    candidates = find_near_neighbors_E8(trees, leaf_codes, q, A, B, l, w, M) \n",
    "\n",
    "    # 5. 计算 近似 k近邻\n",
    "    approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "    # 6. 评估\n",
    "    recall, error, s = metrics(candidates, \n",
    "                   approximate_neighbors, \n",
    "                   k_near_neighbors[i], \n",
    "                   q, train_sift)\n",
    "\n",
    "    recall_arr.append(recall)\n",
    "    error_arr.append(error)\n",
    "    selectivity_arr.append(s)\n",
    "\n",
    "print('L = {}, W = {}'.format(l, w))\n",
    "print('recall = {:.4f}'.format(sum(recall_arr) / len(test_sift)))\n",
    "print('error  = {:.4f}'.format(sum(error_arr) / len(test_sift)))\n",
    "print('selevtivity = {:.4f}'.format(sum(selectivity_arr) / len(test_sift)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Z^M$ multiprobe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "score(\\pi_t) = \\Sigma_{i=1}^M\\Delta_i^2(\\delta_{t,i}) \\\\\n",
    "\\Delta_i(\\delta) = \\delta \\cdot[h_i+\\frac{1}{2}(1 + \\delta)-\\frac{a_i\\cdot v + b_i}{W}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probe_order(q, a, b, W, M):\n",
    "    real_h = (a.dot(q) + b) / W # 真实 hash 值\n",
    "    h = np.floor(real_h)  # 向下取整\n",
    "    positive = h - real_h + 1  # delta 取 1\n",
    "    negative = -(h - real_h)  # delta 取 -1\n",
    "    order = np.argsort(np.append(positive, negative)) # 排序\n",
    "    sign = np.append(np.repeat(1, M), np.repeat(-1, M)) # 符号\n",
    "    return order % M, sign[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_probe_order(q, A[0], B[0], w, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_near_neighbors_multiprobe(trees, leaf_codes, q, A, B, L, W, M, T=0):\n",
    "    result = []\n",
    "    for i, code in enumerate(leaf_codes):\n",
    "        tree = trees[i]\n",
    "        node = tree[code]\n",
    "        for j in range(L):\n",
    "            h = np.floor((A[j].dot(q) + B[j]) / W)\n",
    "            bi = generate_md5(h)\n",
    "            if bi in node[j]:\n",
    "                result.append(node[j][bi])\n",
    "            # probe\n",
    "            t = 0\n",
    "            current_pos = 0\n",
    "            order, sign = get_probe_order(q, A[j], B[j], W, M)\n",
    "            while t < T and current_pos < len(order):\n",
    "                new_h = h.copy()\n",
    "                new_h[order[current_pos]] += sign[current_pos]\n",
    "                bi = generate_md5(new_h)\n",
    "                if bi in node[j]:\n",
    "                    result.append(node[j][bi])\n",
    "                    t += 1\n",
    "                current_pos += 1\n",
    "                \n",
    "    return np.unique(np.concatenate(np.array(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "W =  np.arange(900, 2100, 100)\n",
    "M = 8\n",
    "K = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "metric_results['ZM_Multiprobe'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for l in L:\n",
    "    for w in W:\n",
    "        # 1. 构造 rp 树\n",
    "        forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "        # 2. 构造 hash table\n",
    "        A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "        trees = construct_tables(forest, train_sift, A, B, l, w)\n",
    "        \n",
    "        result = dict()\n",
    "        result['params'] = dict()\n",
    "        result['params']['L'] = l\n",
    "        result['params']['W'] = w\n",
    "        \n",
    "        print('L = {}, W = {}'.format(l, w))\n",
    "        recall_arr = []\n",
    "        error_arr = []\n",
    "        selectivity_arr = []\n",
    "\n",
    "        # 3. 查询点\n",
    "        for i, q in enumerate(test_sift):\n",
    "            leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "            # 4. 获取 候选集 candidates multiprobe\n",
    "            candidates = find_near_neighbors_multiprobe(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "            # 5. 计算 近似 k近邻\n",
    "            approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "            # 6. 评估\n",
    "            recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[i], \n",
    "                           q, train_sift)\n",
    "\n",
    "            recall_arr.append(recall)\n",
    "            error_arr.append(error)\n",
    "            selectivity_arr.append(s)\n",
    "            \n",
    "        result['metrics'] = dict()\n",
    "        result['metrics']['recall'] = sum(recall_arr) / len(test_sift)\n",
    "        result['metrics']['error'] = sum(error_arr) / len(test_sift)\n",
    "        result['metrics']['selectivity'] = sum(selectivity_arr) / len(test_sift)\n",
    "    \n",
    "        metric_results['ZM_Multiprobe'].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_arr_ZM_Multiprobe = []\n",
    "error_arr_ZM_Multiprobe = []\n",
    "selectivity_arr_ZM_Multiprobe = []\n",
    "for result in metric_results['ZM_Multiprobe']:\n",
    "    selectivity_arr_ZM_Multiprobe.append(result['metrics']['selectivity'])\n",
    "    recall_arr_ZM_Multiprobe.append(result['metrics']['recall'])\n",
    "    error_arr_ZM_Multiprobe.append(result['metrics']['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr_ZM_Multiprobe, recall_arr_ZM_Multiprobe, marker='x', label='recall ratio')\n",
    "plt.plot(selectivity_arr_ZM_Multiprobe, error_arr_ZM_Multiprobe, marker='x', label='error ratio')\n",
    "plt.title('Multiprobe, $Z^M$, M=8, L=10', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "w = 1100\n",
    "# 1. 构造 rp 树\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "# 2. 构造 hash table\n",
    "A, B = generate_AB(d=d, L=l, M=M, W=w)\n",
    "trees = construct_tables(forest, train_sift, A, B, l, w)\n",
    "\n",
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "# 3. 查询点\n",
    "for i, q in enumerate(test_sift):\n",
    "    leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "    # 4. 获取 候选集 candidates multiprobe\n",
    "    candidates = find_near_neighbors_multiprobe(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "    # 5. 计算 近似 k近邻\n",
    "    approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "    # 6. 评估\n",
    "    recall, error, s = metrics(candidates, \n",
    "                   approximate_neighbors, \n",
    "                   k_near_neighbors[i], \n",
    "                   q, train_sift)\n",
    "\n",
    "    recall_arr.append(recall)\n",
    "    error_arr.append(error)\n",
    "    selectivity_arr.append(s)\n",
    "\n",
    "print('L = {}, W = {}'.format(l, w))\n",
    "print('recall = {:.4f}'.format(sum(recall_arr) / len(test_sift)))\n",
    "print('error  = {:.4f}'.format(sum(error_arr) / len(test_sift)))\n",
    "print('selevtivity = {:.4f}'.format(sum(selectivity_arr) / len(test_sift)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $E_8$ multiprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "positions_1 = []\n",
    "for i in itertools.combinations(range(8), 2):\n",
    "    positions_1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = []\n",
    "for i in itertools.product(range(-1, 2, 2), repeat=2):\n",
    "    signs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_1 = np.zeros((112, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for position in positions:\n",
    "    for sign in signs:\n",
    "        type_1[i][position[0]] = sign[0]\n",
    "        type_1[i][position[1]] = sign[1]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_2 = np.zeros((128, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_2[:] = 0.5\n",
    "type_2[1] = -0.5\n",
    "type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_2 = []\n",
    "for i in [2, 4, 6]:\n",
    "    for j in itertools.combinations(range(8), i):\n",
    "        positions_2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "for position in positions_2:\n",
    "    for j in position:\n",
    "        type_2[i][j] *= -1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors\n",
    "# type_1, type_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_near_neighbors_E8_multiprobe(trees, leaf_codes, q, A, B, L, W, M, T=0):\n",
    "    result = []\n",
    "    for i, code in enumerate(leaf_codes):\n",
    "        tree = trees[i]\n",
    "        node = tree[code]\n",
    "        for j in range(L):\n",
    "            E8 = node[j] # morton curve\n",
    "            h = (A[j].dot(q) + B[j]) / W\n",
    "            E8_code = E8_decode(h)\n",
    "            \n",
    "            bi = generate_md5(E8_code)\n",
    "            if bi in E8:\n",
    "                result.append(E8[bi])\n",
    "            \n",
    "            # 112 neighbor\n",
    "            neighbor_1 = type_1 + E8_code\n",
    "            distance_1 = np.array([dis.euclidean(h, neighbor) for neighbor in neighbor_1])\n",
    "            \n",
    "            # 128 neighbor\n",
    "            neighbor_2 = type_2 + E8_code\n",
    "            distance_2 = np.array([dis.euclidean(h, neighbor) for neighbor in neighbor_2])\n",
    "            \n",
    "            distance = np.append(distance_1, distance_2)\n",
    "            order = distance.argsort()\n",
    "            \n",
    "            t = 0\n",
    "            i = 0\n",
    "            while t < T and i < 240:\n",
    "                if order[i] >= 112:\n",
    "                    probe_h = neighbor_2[order[i] - 112]\n",
    "                else:\n",
    "                    probe_h = neighbor_1[order[i]]\n",
    "                bi = generate_md5(probe_h)\n",
    "                if bi in E8:\n",
    "                    result.append(E8[bi])\n",
    "                    t += 1\n",
    "                i += 1\n",
    "            \n",
    "    return np.unique(np.concatenate(np.array(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "W =  np.arange(800, 2100, 100)\n",
    "M = 8\n",
    "K = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results['E8_Multiprobe'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for l in L:\n",
    "    for w in W:\n",
    "        # 1. 构造 rp 树\n",
    "        forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "        # 2. 构造 hash table\n",
    "        A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "        trees = construct_tables_E8(forest, train_sift, A, B, l, w)\n",
    "        \n",
    "        result = dict()\n",
    "        result['params'] = dict()\n",
    "        result['params']['L'] = l\n",
    "        result['params']['W'] = w\n",
    "        \n",
    "        print('L = {}, W = {}'.format(l, w))\n",
    "        recall_arr = []\n",
    "        error_arr = []\n",
    "        selectivity_arr = []\n",
    "\n",
    "        # 3. 查询点\n",
    "        for i, q in enumerate(test_sift):\n",
    "            leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "            # 4. 获取 候选集 candidates multiprobe\n",
    "            candidates = find_near_neighbors_E8_multiprobe(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "            # 5. 计算 近似 k近邻\n",
    "            approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "            # 6. 评估\n",
    "            recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[i], \n",
    "                           q, train_sift)\n",
    "\n",
    "            recall_arr.append(recall)\n",
    "            error_arr.append(error)\n",
    "            selectivity_arr.append(s)\n",
    "            \n",
    "        result['metrics'] = dict()\n",
    "        result['metrics']['recall'] = sum(recall_arr) / len(test_sift)\n",
    "        result['metrics']['error'] = sum(error_arr) / len(test_sift)\n",
    "        result['metrics']['selectivity'] = sum(selectivity_arr) / len(test_sift)\n",
    "    \n",
    "        metric_results['E8_Multiprobe'].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_arr_E8_multiprobe = []\n",
    "error_arr_E8_multiprobe = []\n",
    "selectivity_arr_E8_multiprobe = []\n",
    "for result in metric_results['E8_Multiprobe']:\n",
    "    selectivity_arr_E8_multiprobe.append(result['metrics']['selectivity'])\n",
    "    recall_arr_E8_multiprobe.append(result['metrics']['recall'])\n",
    "    error_arr_E8_multiprobe.append(result['metrics']['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr_E8_multiprobe, recall_arr_E8_multiprobe, marker='x', label='recall ratio')\n",
    "plt.plot(selectivity_arr_E8_multiprobe, error_arr_E8_multiprobe, marker='x', label='error ratio')\n",
    "plt.title('Multiprobe, $E_8$, M=8, L=10', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "w = 1100\n",
    "# 1. 构造 rp 树\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "# 2. 构造 hash table\n",
    "A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "trees = construct_tables_E8(forest, train_sift, A, B, l, w)\n",
    "\n",
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "\n",
    "# 3. 查询点\n",
    "for i, q in enumerate(test_sift):\n",
    "    leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "    # 4. 获取 候选集 candidates multiprobe\n",
    "    candidates = find_near_neighbors_E8_multiprobe(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "    # 5. 计算 近似 k近邻\n",
    "    approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "    # 6. 评估\n",
    "    recall, error, s = metrics(candidates, \n",
    "                   approximate_neighbors, \n",
    "                   k_near_neighbors[i], \n",
    "                   q, train_sift)\n",
    "\n",
    "    recall_arr.append(recall)\n",
    "    error_arr.append(error)\n",
    "    selectivity_arr.append(s)\n",
    "\n",
    "print('L = {}, W = {}'.format(l, w))\n",
    "print('recall = {:.4f}'.format(sum(recall_arr) / len(test_sift)))\n",
    "print('error  = {:.4f}'.format(sum(error_arr) / len(test_sift)))\n",
    "print('selevtivity = {:.4f}'.format(sum(selectivity_arr) / len(test_sift)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hierarchical $Z^M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morton Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level 2: Store points into buckets')\n",
    "\n",
    "def construct_tables_morton_curve(forest, P, A, B, L, W):\n",
    "    trees = [] # n trees\n",
    "    for tree in forest:\n",
    "        nodes = dict() # 16 nodes\n",
    "        stack = [tree['root']]\n",
    "        while len(stack) != 0:\n",
    "            node = stack.pop()\n",
    "            if 'idxs' not in node:\n",
    "                stack.append((node['r']))\n",
    "                stack.append((node['l']))\n",
    "            else:\n",
    "                code = node['code']\n",
    "                tables = [] # L buckets\n",
    "                idxs = node['idxs']\n",
    "\n",
    "                # Level 2\n",
    "                for i in range(L):\n",
    "                    curves = dict() # n bucket\n",
    "                    H = np.floor((P[idxs].dot(A[i].T) + B[i]) / W)\n",
    "                    \n",
    "                    min_number = H.min()\n",
    "                    if min_number < 0:\n",
    "                        addition_number = -(H.min() - 1)\n",
    "                    else:\n",
    "                        addition_number = 0\n",
    "\n",
    "                    curves['addition_number'] = addition_number\n",
    "                    \n",
    "                    H += addition_number\n",
    "                    H = H.astype(np.int)\n",
    "                    max_bit = len(bin(H.max())[2:])\n",
    "                    curves['max_bit'] = max_bit\n",
    "                    \n",
    "                    morton_number = np.array([morton_curve(h, max_bit=max_bit) for h in H])\n",
    "                    \n",
    "                    buckets = dict()\n",
    "                    \n",
    "                    for j, number in enumerate(morton_number): # morton 唯一标识\n",
    "                        if number in buckets:\n",
    "                            buckets[number].append(idxs[j])\n",
    "                        else:\n",
    "                            buckets[number] = [idxs[j]]\n",
    "                    \n",
    "                    morton_number.sort()\n",
    "                    curves['morton_number'] = morton_number # morton 码索引列表\n",
    "                    curves['buckets'] = buckets\n",
    "                    \n",
    "                    tables.append(curves)\n",
    "\n",
    "                nodes[code] = tables\n",
    "\n",
    "        trees.append(nodes)\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_near_neighbors_morton(trees, leaf_codes, q, A, B, L, W, M, T=0):\n",
    "    result = []\n",
    "    for i, code in enumerate(leaf_codes):\n",
    "        tree = trees[i]\n",
    "        node = tree[code]\n",
    "        for j in range(L):\n",
    "            curve = node[j] # morton curve\n",
    "            h = np.floor((A[j].dot(q) + B[j]) / W)\n",
    "            h += curve['addition_number']\n",
    "            h = h.astype(np.int)\n",
    "            \n",
    "            morton_number = morton_curve(h, curve['max_bit'])\n",
    "            \n",
    "            idx = np.argwhere(curve['morton_number'] < morton_number)\n",
    "            if len(idx) == 0: # 最小\n",
    "                idx = 0\n",
    "            elif len(idx) == len(curve['morton_number']):\n",
    "                idx = idx[-2][0]\n",
    "            elif len(idx) == len(curve['morton_number']) - 1:\n",
    "                idx = idx[-3][0]\n",
    "            else:\n",
    "                idx = idx[-1][0]\n",
    "\n",
    "            m1 = curve['morton_number'][idx]            \n",
    "            # print(idx)\n",
    "            if morton_number in curve['buckets']:\n",
    "                result.append(curve['buckets'][morton_number])\n",
    "                m2 = curve['morton_number'][idx + 2]\n",
    "            else:\n",
    "                m2 = curve['morton_number'][idx + 1]\n",
    "            \n",
    "            # probe\n",
    "            t = 0\n",
    "            result.append(curve['buckets'][m1])\n",
    "            result.append(curve['buckets'][m2])\n",
    "                \n",
    "    return np.unique(np.concatenate(np.array(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [10]\n",
    "W =  np.arange(800, 2100, 100)\n",
    "M = 8\n",
    "K = 50\n",
    "n, d = train_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results['ZM_hierarchical'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for l in L:\n",
    "    for w in W:\n",
    "        # 1. 构造 rp 树\n",
    "        forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "        # 2. 构造 hash table\n",
    "        A, B = generate_AB(d=d, L=l, M=M, W=w, random_state=1)\n",
    "\n",
    "        trees = construct_tables_morton_curve(forest, train_sift, A, B, l, w)\n",
    "        \n",
    "        result = dict()\n",
    "        result['params'] = dict()\n",
    "        result['params']['L'] = l\n",
    "        result['params']['W'] = w\n",
    "        \n",
    "        print('L = {}, W = {}'.format(l, w))\n",
    "        recall_arr = []\n",
    "        error_arr = []\n",
    "        selectivity_arr = []\n",
    "\n",
    "        # 3. 查询点\n",
    "        for i, q in enumerate(test_sift):\n",
    "            leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "            # 4. 获取 候选集 candidates multiprobe\n",
    "            candidates = find_near_neighbors_morton(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "            # 5. 计算 近似 k近邻\n",
    "            approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "            # 6. 评估\n",
    "            recall, error, s = metrics(candidates, \n",
    "                           approximate_neighbors, \n",
    "                           k_near_neighbors[i], \n",
    "                           q, train_sift)\n",
    "\n",
    "            recall_arr.append(recall)\n",
    "            error_arr.append(error)\n",
    "            selectivity_arr.append(s)\n",
    "\n",
    "        result['metrics'] = dict()\n",
    "        result['metrics']['recall'] = sum(recall_arr) / len(test_sift)\n",
    "        result['metrics']['error'] = sum(error_arr) / len(test_sift)\n",
    "        result['metrics']['selectivity'] = sum(selectivity_arr) / len(test_sift)\n",
    "    \n",
    "        metric_results['ZM_hierarchical'].append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "recall_arr_ZM_hierarchical = []\n",
    "error_arr_ZM_hierarchical = []\n",
    "selectivity_arr_ZM_hierarchical = []\n",
    "for result in metric_results['ZM_hierarchical']:\n",
    "    selectivity_arr_ZM_hierarchical.append(result['metrics']['selectivity'])\n",
    "    recall_arr_ZM_hierarchical.append(result['metrics']['recall'])\n",
    "    error_arr_ZM_hierarchical.append(result['metrics']['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr_ZM_hierarchical, recall_arr_ZM_hierarchical, marker='x', label='recall ratio')\n",
    "plt.plot(selectivity_arr_ZM_hierarchical, error_arr_ZM_hierarchical, marker='x', label='error ratio')\n",
    "plt.title('Multiprobe, $E_8$, M=8, L=10', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 10\n",
    "w = 1100\n",
    "# 1. 构造 rp 树\n",
    "forest = rp_forest_normal(P=train_sift, max_depth=4)\n",
    "# 2. 构造 hash table\n",
    "A, B = generate_AB(d=d, L=l, M=M, W=w)\n",
    "trees = construct_tables_morton_curve(forest, train_sift, A, B, l, w)\n",
    "\n",
    "recall_arr = []\n",
    "error_arr = []\n",
    "selectivity_arr = []\n",
    "# 3. 查询点\n",
    "for i, q in enumerate(test_sift):\n",
    "    leaf_codes = find_leaf_codes(forest, q)\n",
    "\n",
    "    # 4. 获取 候选集 candidates multiprobe\n",
    "    candidates = find_near_neighbors_morton(trees, leaf_codes, q, A, B, l, w, M, T=1) \n",
    "\n",
    "    # 5. 计算 近似 k近邻\n",
    "    approximate_neighbors = find_k_nearest_neighbors(train_sift, q, candidates)\n",
    "\n",
    "    # 6. 评估\n",
    "    recall, error, s = metrics(candidates, \n",
    "                   approximate_neighbors, \n",
    "                   k_near_neighbors[i], \n",
    "                   q, train_sift)\n",
    "\n",
    "    recall_arr.append(recall)\n",
    "    error_arr.append(error)\n",
    "    selectivity_arr.append(s)\n",
    "\n",
    "print('L = {}, W = {}'.format(l, w))\n",
    "print('recall = {:.4f}'.format(sum(recall_arr) / len(test_sift)))\n",
    "print('error  = {:.4f}'.format(sum(error_arr) / len(test_sift)))\n",
    "print('selevtivity = {:.4f}'.format(sum(selectivity_arr) / len(test_sift)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hierarchical $E_8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_E8(E8_codes):\n",
    "    E8_codes_unique = np.unique(E8_codes, axis=0)\n",
    "    \n",
    "    temp = E8_codes_unique.copy()\n",
    "    m = 0\n",
    "    temp_levels = []\n",
    "    while len(temp) != 1:\n",
    "        m += 1\n",
    "        temp /= 2\n",
    "        temp = np.array([E8_decode(code) for code in temp])\n",
    "        temp = np.unique(temp, axis=0)\n",
    "        \n",
    "        current_temp = temp * (2 ** m) # current level HE8 code\n",
    "        temp_levels.append(np.array([generate_md5(code) for code in current_temp]))\n",
    "\n",
    "    print(m)\n",
    "\n",
    "    temp_levels = np.array(temp_levels)\n",
    "\n",
    "    levels = dict()\n",
    "    node = dict()\n",
    "    node['code'] = temp_levels[-1][0]\n",
    "    levels['root'] = node\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Level 2: Store points into buckets')\n",
    "\n",
    "def construct_tables_E8_hierarchical(forest, P, A, B, L, W):\n",
    "    trees = [] # n trees\n",
    "    for tree in forest:\n",
    "        nodes = dict() # 16 nodes\n",
    "        stack = [tree['root']]\n",
    "        while len(stack) != 0:\n",
    "            node = stack.pop()\n",
    "            if 'idxs' not in node:\n",
    "                stack.append((node['r']))\n",
    "                stack.append((node['l']))\n",
    "            else:\n",
    "                code = node['code']\n",
    "                tables = [] # L buckets\n",
    "                idxs = node['idxs']\n",
    "\n",
    "                # Level 2\n",
    "                for i in range(L):\n",
    "                    E8 = dict() # n bucket\n",
    "                    E8_codes = []\n",
    "                    H = (P[idxs].dot(A[i].T) + B[i]) / W\n",
    "                    \n",
    "                    for j, h in enumerate(H):\n",
    "                        E8_code = E8_decode(h)\n",
    "                        E8_codes.append(E8_code)\n",
    "                        bi = generate_md5(E8_code)\n",
    "                        if bi in E8:\n",
    "                            E8[bi].append(idxs[j])\n",
    "                        else:\n",
    "                            E8[bi] = [idxs[j]]\n",
    "                    level_E8 = hierarchical_E8(E8_codes)\n",
    "                    tables.append(E8)\n",
    "\n",
    "                nodes[code] = tables\n",
    "\n",
    "        trees.append(nodes)\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recall_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.02, 0.8, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8, recall_arr_E8, marker='x', label='$E_8$ Standard')\n",
    "plt.plot(selectivity_arr_E8_multiprobe, recall_arr_E8_multiprobe, marker='x', label='$E_8$ Multiprobe')\n",
    "plt.plot(selectivity_arr_ZM_Multiprobe, recall_arr_ZM_Multiprobe, marker='x', label='$Z^M$ Multiprobe')\n",
    "plt.plot(selectivity_arr_ZM_hierarchical, recall_arr_ZM_hierarchical, marker='x', label='$Z^M$ Hierarchical')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, error_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8, error_arr_E8, marker='x', label='$E_8$ Standard')\n",
    "plt.plot(selectivity_arr_E8_multiprobe, error_arr_E8_multiprobe, marker='x', label='$E_8$ Multiprobe')\n",
    "plt.plot(selectivity_arr_ZM_Multiprobe, error_arr_ZM_Multiprobe, marker='x', label='$Z^M$ Multiprobe')\n",
    "plt.plot(selectivity_arr_ZM_hierarchical, error_arr_ZM_hierarchical, marker='x', label='$Z^M$ Hierarchical')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8, recall_arr_E8, marker='x', label='$E_8$ Standard')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8_multiprobe, recall_arr_E8_multiprobe, marker='x', label='$E_8$ Multiprobe')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_ZM_Multiprobe, recall_arr_ZM_Multiprobe, marker='x', label='$Z^M$ Multiprobe')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, recall_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_ZM_hierarchical, recall_arr_ZM_hierarchical, marker='x', label='$Z^M$ Hierarchical')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, error_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8, error_arr_E8, marker='x', label='$E_8$ Standard')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, error_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_E8_multiprobe, error_arr_E8_multiprobe, marker='x', label='$E_8$ Multiprobe')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, error_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_ZM_Multiprobe, error_arr_ZM_Multiprobe, marker='x', label='$Z^M$ Multiprobe')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selectivity_arr, error_arr, marker='x', label='$Z^M$ Standard')\n",
    "plt.plot(selectivity_arr_ZM_hierarchical, error_arr_ZM_hierarchical, marker='x', label='$Z^M$ Hierarchical')\n",
    "plt.title('M=8, L=10, K=50', fontsize=12)\n",
    "plt.xlabel('selectivity', fontsize=12)\n",
    "plt.ylabel('quality', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "902px",
    "left": "213px",
    "top": "117px",
    "width": "251px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
